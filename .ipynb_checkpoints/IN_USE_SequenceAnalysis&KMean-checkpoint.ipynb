{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from __future__ import print_function\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve cost spreadsheets\n",
    "costs_sub = pd.DataFrame.from_csv('./SubstitutionCosts_v2.csv')\n",
    "#costs_del = pd.DataFrame.from_csv('./SubstitutionCosts.csv')\n",
    "#costs_ins = pd.DataFrame.from_csv('./SubstitutionCosts.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost functions which returns cost from lookup in costmartix \n",
    "# We will update the definition once we have the cost matrix\n",
    "\n",
    "def costDeletion(s):\n",
    "    return int(1)\n",
    "\n",
    "def costInsertion(s):\n",
    "    return int(1)\n",
    "\n",
    "def costSubstitution(s1, s2):\n",
    "    return costs_sub.get_value(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does the sequence analysis between job-sequences of two different persons\n",
    "def OptimalMatching(s1, s2):\n",
    "    \n",
    "    lenstr1 = len(s1)\n",
    "    lenstr2 = len(s2)\n",
    "    cost = np.zeros((lenstr1 + 1, lenstr2 + 1), dtype=int)\n",
    "    \n",
    "    # initialization : comparaison with a null sequence\n",
    "    min_cost = 1\n",
    "    for i in range(lenstr1 + 1):\n",
    "        cost[i, 0] = i*min_cost\n",
    "    for j in range(lenstr2 + 1):\n",
    "        cost[0, j] = j*min_cost\n",
    "\n",
    "    for el1 in range(lenstr1):\n",
    "        for el2 in range(lenstr2):\n",
    "            if s1[el1] == s2[el2]:\n",
    "                cost[el1 + 1, el2 + 1] = cost[el1, el2] # cost = 0 because they are the same\n",
    "            else:\n",
    "                cost[el1 + 1, el2 + 1] = min(\n",
    "                                           cost[el1, el2 + 1] + costDeletion(s2[el2]), # deletion\n",
    "                                           cost[el1 + 1, el2] + costInsertion(s1[el1]), # insertion\n",
    "                                           cost[el1, el2] + costSubstitution(s1[el1],s2[el2]) # substitution\n",
    "                                          )\n",
    "    return cost[lenstr1, lenstr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input is career matrix of all the persons\n",
    "# Does the sequence analysis between everypair and returns a Distance Matrix.\n",
    "def SequenceAnalysis(careers):\n",
    "    maxLen = len(careers)\n",
    "    costTable = np.zeros((maxLen, maxLen), dtype=int)\n",
    "    #for i in range(len(careers))):\n",
    "    for i in tqdm(range(len(careers))):\n",
    "        for j in range(len(careers)):\n",
    "            costTable[i][j] = OptimalMatching(careers[i],careers[j])\n",
    "    return costTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For Testing\n",
    "#seq1 = [\"job1\",\"job2\",\"job3\"]\n",
    "#seq2 = [\"job1\",\"job3\"]\n",
    "#print(OptimalMatching(seq1, seq2))\n",
    "\n",
    "new_trajs = pickle.load(open('./recoded_trajs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# For Testing\n",
    "#list = [[\"job1\",\"job2\",\"job3\"],[\"job1\",\"job3\"],[\"job1\",\"job6\"]]\n",
    "\n",
    "#For testing\n",
    "#new_trajs = new_trajs[:10]\n",
    "\n",
    "table = SequenceAnalysis(new_trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  3,  9, ...,  6,  5,  4],\n",
       "       [ 3,  0,  9, ...,  7,  8,  6],\n",
       "       [ 9,  9,  0, ...,  8, 10,  8],\n",
       "       ..., \n",
       "       [ 6,  7,  8, ...,  0,  3,  4],\n",
       "       [ 5,  8, 10, ...,  3,  0,  3],\n",
       "       [ 4,  6,  8, ...,  4,  3,  0]], dtype=int64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pickle.dump(table,open('pairwise_v2.p','wb'))\n",
    "table = pickle.load(open('pairwise_v2.p','rb'),encoding='latin1')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions used for clustering (below)**. Takes three arguments- DistanceMatrix after Sequence Analysis, number of clusters, number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_average_distance(i,j,list_clusters):\n",
    "    list_cluster_elements = list_clusters[j]\n",
    "    distance = []\n",
    "    for p in list_cluster_elements:\n",
    "        distance.append(table[i][p])\n",
    "    if float(len(distance))!= 0:\n",
    "        return sum(distance) / float(len(distance))\n",
    "    else:\n",
    "        print(\"Distance Zero\")\n",
    "        return sum(distance)\n",
    "\n",
    "def distribute_initialClusters(no_left_rows,no_clusters,list_clusters):\n",
    "    for i in range(no_left_rows):\n",
    "        cluster_similarity = np.zeros(no_clusters,np.int)\n",
    "        for j in range(no_clusters):\n",
    "            cluster_similarity[j] = compute_average_distance(i,j,list_clusters)\n",
    "        cluster_belong = np.argmin(cluster_similarity)\n",
    "        list_clusters[cluster_belong].append(no_clusters+i)\n",
    "\n",
    "def clustering(table, no_clusters, no_iterations):\n",
    "    list_clusters = []#{}\n",
    "    for i in range(no_clusters):\n",
    "        tempList = []\n",
    "        tempList.append(i)\n",
    "        list_clusters.append(tempList)#list_clusters[i] = tempList\n",
    "    no_rows = table.shape[0]\n",
    "    no_left_rows = no_rows - no_clusters\n",
    "    distribute_initialClusters(no_left_rows,no_clusters,list_clusters)\n",
    "    for p in tqdm(range(no_iterations)):\n",
    "        for i in range(no_rows):\n",
    "            cluster_similarity = np.zeros(no_clusters,np.int)\n",
    "            earlier_cluster = -1\n",
    "            for j in range(no_clusters):\n",
    "                temp = list_clusters[j]\n",
    "                if i in temp:\n",
    "                    earlier_cluster = j\n",
    "            for j in range(no_clusters):\n",
    "                cluster_similarity[j] = compute_average_distance(i,j,list_clusters)\n",
    "            cluster_belong = np.argmin(cluster_similarity)\n",
    "            list_clusters[cluster_belong].append(i)\n",
    "            list_clusters[earlier_cluster].remove(i)\n",
    "        if sum([len(list_clusters[i]) for i in range(no_clusters)]) != no_rows:\n",
    "            print(\"Error: More number of elements in cluster\")\n",
    "            print(\"Iteration p\")\n",
    "            break\n",
    "    return list_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Clusters below contain the final clusters as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Results are for v2:\n",
    "list_clusters = clustering(table,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "973\n",
      "67\n",
      "183\n",
      "43\n",
      "339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(list_clusters[0]))\n",
    "print(len(list_clusters[1]))\n",
    "print(len(list_clusters[2]))\n",
    "print(len(list_clusters[3]))\n",
    "print(len(list_clusters[4]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list_clusters,open('clusters_v2_Problems.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
