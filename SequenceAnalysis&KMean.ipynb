{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named tqdm",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-7370a09f55fa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named tqdm"
     ]
    }
   ],
   "source": [
    "import pdb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from __future__ import print_function\n",
    "from tqdm import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Retrieve cost spreadsheets\n",
    "#costs_sub = pd.DataFrame.from_csv('./SubstitutionCosts_v2.csv')\n",
    "#costs_del = pd.DataFrame.from_csv('./SubstitutionCosts.csv')\n",
    "#costs_ins = pd.DataFrame.from_csv('./SubstitutionCosts.csv')\n",
    "\n",
    "costs = pd.DataFrame.from_csv('./Costs_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cost functions which returns cost from lookup in costmartix \n",
    "# We will update the definition once we have the cost matrix\n",
    "\n",
    "def costDeletion(s):\n",
    "    return costs.get_value(s,'Del')\n",
    "\n",
    "def costInsertion(s):\n",
    "    return costs.get_value('Ins',s)\n",
    "\n",
    "def costSubstitution(s1, s2):\n",
    "    return costs.get_value(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Does the sequence analysis between job-sequences of two different persons\n",
    "def OptimalMatching(s1, s2):\n",
    "    \n",
    "    lenstr1 = len(s1)\n",
    "    lenstr2 = len(s2)\n",
    "    cost = np.zeros((lenstr1 + 1, lenstr2 + 1), dtype=int)\n",
    "    \n",
    "    # initialization : comparaison with a null sequence\n",
    "    min_cost = 1\n",
    "    for i in range(lenstr1 + 1):\n",
    "        cost[i, 0] = i*min_cost\n",
    "    for j in range(lenstr2 + 1):\n",
    "        cost[0, j] = j*min_cost\n",
    "\n",
    "    for el1 in range(lenstr1):\n",
    "        for el2 in range(lenstr2):\n",
    "            if s1[el1] == s2[el2]:\n",
    "                cost[el1 + 1, el2 + 1] = cost[el1, el2] # cost = 0 because they are the same\n",
    "            else:\n",
    "                cost[el1 + 1, el2 + 1] = min(\n",
    "                                           cost[el1, el2 + 1] + costDeletion(s2[el2]), # deletion\n",
    "                                           cost[el1 + 1, el2] + costInsertion(s1[el1]), # insertion\n",
    "                                           cost[el1, el2] + costSubstitution(s1[el1],s2[el2]) # substitution\n",
    "                                          )\n",
    "    return cost[lenstr1, lenstr2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input is career matrix of all the persons\n",
    "# Does the sequence analysis between everypair and returns a Distance Matrix.\n",
    "def SequenceAnalysis(careers):\n",
    "    maxLen = len(careers)\n",
    "    costTable = np.zeros((maxLen, maxLen), dtype=int)\n",
    "    #for i in range(len(careers))):\n",
    "    for i in tqdm(range(len(careers))):\n",
    "        for j in range(len(careers)):\n",
    "            costTable[i][j] = OptimalMatching(careers[i],careers[j])\n",
    "    return costTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_trajs = pickle.load(open('./recoded_trajs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are for\n",
    "table = SequenceAnalysis(new_trajs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  7, 21, ...,  7,  8,  9],\n",
       "       [ 9,  0, 21, ...,  7, 12,  9],\n",
       "       [22, 22,  0, ...,  9, 14, 14],\n",
       "       ..., \n",
       "       [ 8,  7,  9, ...,  0,  6,  4],\n",
       "       [ 7, 11, 13, ...,  5,  0,  6],\n",
       "       [ 9,  8, 13, ...,  4,  6,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pickle.dump(table,open('pairwise_v4.p','wb'))\n",
    "#table = pickle.load(open('pairwise_v2.p','rb'),encoding='latin1')\n",
    "table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Functions used for clustering (below)**. Takes three arguments- DistanceMatrix after Sequence Analysis, number of clusters, number of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def compute_average_distance(i,j,list_clusters):\n",
    "    list_cluster_elements = list_clusters[j]\n",
    "    distance = []\n",
    "    for p in list_cluster_elements:\n",
    "        distance.append(table[i][p])\n",
    "    if float(len(distance))!= 0:\n",
    "        return sum(distance) / float(len(distance))\n",
    "    else:\n",
    "        print(\"Distance Zero\")\n",
    "        return sum(distance)\n",
    "\n",
    "def distribute_initialClusters(no_left_rows,no_clusters,list_clusters):\n",
    "    for i in range(no_left_rows):\n",
    "        cluster_similarity = np.zeros(no_clusters,np.int)\n",
    "        for j in range(no_clusters):\n",
    "            cluster_similarity[j] = compute_average_distance(i,j,list_clusters)\n",
    "        cluster_belong = np.argmin(cluster_similarity)\n",
    "        list_clusters[cluster_belong].append(no_clusters+i)\n",
    "\n",
    "def clustering(table, no_clusters, no_iterations):\n",
    "    list_clusters = []#{}\n",
    "    for i in range(no_clusters):\n",
    "        tempList = []\n",
    "        tempList.append(i)\n",
    "        list_clusters.append(tempList)#list_clusters[i] = tempList\n",
    "    no_rows = table.shape[0]\n",
    "    no_left_rows = no_rows - no_clusters\n",
    "    distribute_initialClusters(no_left_rows,no_clusters,list_clusters)\n",
    "    for p in tqdm(range(no_iterations)):\n",
    "        for i in range(no_rows):\n",
    "            cluster_similarity = np.zeros(no_clusters,np.int)\n",
    "            earlier_cluster = -1\n",
    "            for j in range(no_clusters):\n",
    "                temp = list_clusters[j]\n",
    "                if i in temp:\n",
    "                    earlier_cluster = j\n",
    "            for j in range(no_clusters):\n",
    "                cluster_similarity[j] = compute_average_distance(i,j,list_clusters)\n",
    "            cluster_belong = np.argmin(cluster_similarity)\n",
    "            list_clusters[cluster_belong].append(i)\n",
    "            list_clusters[earlier_cluster].remove(i)\n",
    "        if sum([len(list_clusters[i]) for i in range(no_clusters)]) != no_rows:\n",
    "            print(\"Error: More number of elements in cluster\")\n",
    "            print(\"Iteration p\")\n",
    "            break\n",
    "    return list_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List Clusters below contain the final clusters as a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "#Results are for v5:\n",
    "list_clusters4 = clustering(table,4,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "468\n",
      "899\n",
      "112\n",
      "126\n"
     ]
    }
   ],
   "source": [
    "#list_clusters3 = list_clusters\n",
    "\n",
    "for cluster in list_clusters4:\n",
    "    print(len(cluster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(list_clusters4,open('clusters_v4_4.p','wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
